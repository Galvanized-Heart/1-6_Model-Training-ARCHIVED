{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Model Training\n",
    "# Additional Exercises\n",
    "\n",
    "This week, we will revisit the Heart failure dataset that you have seen before. What we want to do is to perform logistic regression on our model and evaluate its accuracy. You will apply what you have learned from the main module to this additional exercise. Below we have imported the necessary modules/packages, as well as preprocessed the data in the same way that was done in the data science portion. Instatiate the model and train the model using the train_scaled and the train_targets. Start with a learning rate of 0.0001 and 100 epochs. Play around with the hyperparameters until you get an accuracy greater than 80%.\n",
    "\n",
    "Below we will provide some guidance. But try and complete the majority of the code yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset\n",
    "df = \n",
    "\n",
    "# TODO: Isolate our target `DEATH_EVENT` and remove the target as well as 'time' from the features\n",
    "target = \n",
    "\n",
    "# Removing time due to target leakage\n",
    "# predictors =\n",
    "predictors = df.drop(['DEATH_EVENT', 'time'], axis = 1)\n",
    "\n",
    "# Split dataset into test and train;DO NOT MODIFY\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test_split(predictors, target, test_size = 0.20, shuffle = True, random_state=7)\n",
    "\n",
    "# Scaling the features\n",
    "sc = StandardScaler()\n",
    "train_scaled = sc.fit_transform(train_inputs.astype(float, 64))\n",
    "test_scaled = sc.transform(test_inputs.astype(float, 64))\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=test_inputs.columns)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=train_inputs.columns)\n",
    "\n",
    "# to keep naming consistent (can use ether variable)\n",
    "train_inputs = train_scaled\n",
    "test_inputs = test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "# TODO: Complete the code to instatiate and train the model here.\n",
    "# Initialize SGDClassifier for logistic regression\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "\n",
    "# Evaluate the model using the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next week's Additional Exercises, you will be evaluating the model you trained on various metrics. After training the model above, save the model using the ```pickle``` library. You can refer to this week's pre-module on how to do this. Save the model with a meaningful name so you can find it later, like ```hf_model.pkl```. Check your folder to make sure it is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "import pickle\n",
    "\n",
    "# TODO: Complete this code\n",
    "with open('hf_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
